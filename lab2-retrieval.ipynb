{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2207dd19",
      "metadata": {
        "id": "2207dd19"
      },
      "source": [
        "# üîç FAISS Similarity Search with Sentence Transformers + RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "678972b0",
      "metadata": {
        "id": "678972b0"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers pymupdf faiss-cpu openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abd2b4d5",
      "metadata": {
        "id": "abd2b4d5"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import fitz  # PyMuPDF\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "import getpass\n",
        "import os\n",
        "import openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "979f2e08",
      "metadata": {
        "id": "979f2e08"
      },
      "outputs": [],
      "source": [
        "# --- Step 1: Download PDFs from arXiv ---\n",
        "pdf_urls = [\n",
        "    \"https://arxiv.org/pdf/2401.15884\",\n",
        "    \"https://arxiv.org/pdf/2005.11401\"\n",
        "]\n",
        "\n",
        "local_paths = []\n",
        "for i, url in enumerate(pdf_urls):\n",
        "    response = requests.get(url)\n",
        "    filename = f\"paper_{i}.pdf\"\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "    local_paths.append(filename)\n",
        "\n",
        "print(f\"Downloaded {len(local_paths)} PDFs.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28324d3e",
      "metadata": {
        "id": "28324d3e"
      },
      "outputs": [],
      "source": [
        "# --- Step 2: Extract text using PyMuPDF ---\n",
        "def extract_text_from_pdf(path):\n",
        "    doc = fitz.open(path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "texts = [extract_text_from_pdf(path) for path in local_paths]\n",
        "full_text = \"\\n\".join(texts)\n",
        "print(f\"Total extracted characters: {len(full_text)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af20ed08",
      "metadata": {
        "id": "af20ed08"
      },
      "outputs": [],
      "source": [
        "# --- Step 3: Split text into overlapping chunks ---\n",
        "def split_text(text, chunk_size=500, overlap=100):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = min(start + chunk_size, len(text))\n",
        "        chunks.append(text[start:end])\n",
        "        start += chunk_size - overlap\n",
        "    return chunks\n",
        "\n",
        "chunks = split_text(full_text)\n",
        "print(f\"Generated {len(chunks)} chunks.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afab8003",
      "metadata": {
        "id": "afab8003"
      },
      "outputs": [],
      "source": [
        "# --- Step 4: Generate embeddings ---\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = model.encode(chunks, convert_to_numpy=True, show_progress_bar=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07597ed7",
      "metadata": {
        "id": "07597ed7"
      },
      "outputs": [],
      "source": [
        "# --- Step 5: Build FAISS index ---\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings)\n",
        "print(f\"FAISS index built with {index.ntotal} vectors.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c94a9d51",
      "metadata": {
        "id": "c94a9d51"
      },
      "outputs": [],
      "source": [
        "# --- Step 6: Similarity search ---\n",
        "def search(query, k=3):\n",
        "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "    print(f\"\\nTop {k} results for: '{query}'\\n\")\n",
        "    for i, idx in enumerate(indices[0]):\n",
        "        print(f\"Result {i+1} (score={distances[0][i]:.2f}):\\n{chunks[idx][:500]}\\n{'-'*80}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03281cf4",
      "metadata": {
        "id": "03281cf4"
      },
      "outputs": [],
      "source": [
        "# --- Step 7: Try some sample questions ---\n",
        "sample_questions = [\n",
        "    \"What is RAG and how does it work?\",\n",
        "    \"What is the difference between RAG-Sequence and RAG-Token?\",\n",
        "    \"How does RAG use non-parametric memory?\",\n",
        "    \"What tasks were used to evaluate RAG?\",\n",
        "    \"How is Dense Passage Retrieval (DPR) used in RAG?\",\n",
        "    \"What is the advantage of hybrid models over purely parametric models?\",\n",
        "    \"What decoding strategies are used in RAG?\",\n",
        "    \"How does RAG compare to T5 and BART?\",\n",
        "    \"What datasets were used to benchmark RAG models?\",\n",
        "    \"Can RAG models be updated without retraining?\"\n",
        "]\n",
        "\n",
        "for q in sample_questions:\n",
        "    search(q, k=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f1c49df",
      "metadata": {
        "id": "6f1c49df"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Securely prompt for your OpenAI API key\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def rag_answer(question, k=2, model_name=\"gpt-4o\"):\n",
        "    query_embedding = model.encode([question], convert_to_numpy=True)\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "    retrieved_context = \"\\n\\n\".join([chunks[i] for i in indices[0]])\n",
        "\n",
        "    prompt = f\"Context:\\n{retrieved_context}\\n\\nAnswer this Question based only on the provided context: {question}\\nAnswer:\"\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based only on the provided context.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].message.content\n",
        "    print(f\"\\nQuestion: {question}\\nAnswer: {answer}\")\n",
        "\n",
        "# üîç Try it out with a real question\n",
        "rag_answer(\"What is retrieval augmented generation?\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}